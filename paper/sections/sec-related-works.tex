% !TEX root = ../convolutional_w2.tex

\section{Related Work}

The original formulation of optimal transportation, introduced in~\cite{Kantorovich42}, involves a linear program connecting a pair of distributions.  The cost of moving density from one point to another is specified using a fixed matrix of pairwise costs. As outlined in~\cite{Burkard09}, a variety of linear program solvers and dedicated combinatorial schemes have been devised for this problem.  These methods scale up to a few thousand variables and were applied to graphics applications in~\cite{bonneel-2011} and in~\cite{lipman-2011}.  They do not scale to large domains such as images with millions of pixels, however, and are not tailored for advanced problems like barycenter computation. 

Specific instances of optimal transportation can be efficiently solved by leveraging tools from computational geometry.  The transportation cost from continuous to pointwise measures, for instance, can be computed either via multiscale algorithms~\cite{Merigot2011,schwartzburg-2014} or through Newton iterations on Euclidean spaces~\cite{degoes-2012,Zhao-2013}.  More recently, this Newton-based approach for optimal transportation was extended to discrete surfaces~\cite{degoes-2014}.  Transportation distances between point clouds and line segments also were approximated in 2D based on a triangulation tiling of the plane and greedy point-to-segment clustering~\cite{degoes-2011}.

Another line of work proposes a dynamical formulation for optimal transportation with an additional time variable.  For squared distance costs, Benamou and Brenier~\shortcite{Benamou2000} compute transportation distances by minimizing the cost of advecting one distribution to another in time.
For non-squared distance costs, Solomon et al.~\shortcite{solomon-2014} solve for transportation maps as the flow of a vector field whose divergence matches the difference between the input densities.

Other methods use optimal transportation to aggregate and average information from multiple densities.  Examples include barycenter computation~\cite{agueh-2011}, density propagation over graphs~\cite{solomon-2014-2}, and computation of ``soft'' correspondence maps~\cite{solomon-2012}.   These problems are typically solved via a multi-marginal linear program~\cite{agueh-2011,kim-2013}, which  is infeasible for large-scale domains.   One work-around approaches the dual of the linear program using L-BFGS with subgradient directions~\cite{Carlier-NumericsBarycenters}, but this strategy suffers from poor conditioning and noisy results.

Regularization provides a promising way to approximate solutions of transportation problems. While interior point methods long have used barrier functions to transform linear programs into strictly convex problems, entropic regularizers in the particular case of optimal transportation provide several key advantages outlined in~\cite{cuturi-2013}. With entropic regularization, optimal transportation is solved using an iterative scaling method known as the iterative proportional fitting procedure (IPFP) or Sinkhorn-Knopp algorithm~\cite{DemingStephanIPFP,sinkhorn1967diagonal}, which can be implemented in parallel GPGPU architectures and used to compute e.g.\ the barycenter of thousands of distributions~\cite{CuturiBarycenter}.

Our work leverages the efficiency of iterative scaling methods for entropy-regularized transport and related problems, principally~\cite{cuturi-2013,Benamou-IterBregman-2014}.  By posing regularized transport in continuous language, we couple the efficiency of these algorithms with discretization on domains like surfaces and images.  This change is not simply notational but rather leads to much faster iteration through connection to Gaussian kernels on images and the heat kernel of a surface; these kernels can be evaluated without precomputing a matrix of pairwise distances.  We demonstrate applications of the resulting methods for large-scale transport on tasks relevant to computer graphics applications.

% static OT -- Justin added a sentence or two summarizing the OT linear program just in case
% The original formulation of optimal transport (OT), introduced in~\cite{Kantorovich42}, involves a linear program (LP) over a product space of couplings between two distributions or histograms.  The cost of moving probabilistic mass from one point or bin to another is specified using a fixed matrix of pairwise values.  A variety of LP solvers and dedicated combinatorial optimization schemes have been devised for this problem, as outlined in~\cite{Burkard09}. These methods scale to medium-size problems up to a few thousand variables and were applied to graphics applications like BRDF interpolation in~\cite{bonneel-2011}. They do not scale to large domains and are not tailored for advanced problems like barycenter computation. Another line of work combines tools from computational geometry with multiscale structures to transport between a discrete and a continuous density on Euclidean space~\cite{Merigot2011}.

% geometric approaches
% It is necessary to use the geometry of the space supporting the distributions (e.g.\ geodesic distance costs) and the sparsity of the optimal coupling to design faster algorithms.% (it is supported on the graph of the optimal transportation plan). % <--- we haven't really introduced this language, and I think we're ok without it
% For squared geodesic distance costs on a manifold, \cite{Benamou2000} provide a dynamical formulation where time-dependent transport is the solution of a convex program involving advection over the domain. The price paid is the introduction of an extra time variable in the initial static OT formulation. For non-squared geodesic distance costs (``Monge's problem''), the transportation map is described by a vector field whose divergence is the difference between the input densities with minimal $L^1$ norm. This problem is solved in~\cite{solomon-2014}, using the resulting OT metric for various geometry problems.

% other variational problems
%The computation of OT distances is just the tip of the iceberg, and i
% In principle, it is possible to integrate OT distances into virtually any optimization problem requiring some sort of geometric discrepancy between probability distributions, but computational methods for this task are less well-explored. Examples of such problems include the computation of OT barycenters~\cite{agueh-2011}, propagation over a graph~\cite{solomon-2014-2}, and computation of ``soft'' maps~\cite{solomon-2012}. This problem is equivalent to a multi-marginal LP~\cite{agueh-2011,kim-2013} that is not tractable numerically. Approximating Wasserstein barycenters on a fixed grid yields a large-scale LP~\cite{Carlier-NumericsBarycenters}, whose complexity makes it difficult apply to graphics applications. One work-around is to solve the dual LP using generic L-BFGS optimization with subgradient directions~\cite{Carlier-NumericsBarycenters}.  These approaches suffer from poor numerical conditioning, and the discretized barycenter generally is noisy due to discretization errors.

% regularization
% A fast, stable classical approach approximating the solutions of LPs is to replace the positivity constraint by a smooth barrier penalty. A popular choice is entropy, an idea dating back to Schr\"odinger~\cite{RuschendorfThomsen}. This barrier provides better-conditioned and strictly convex objectives. Furthermore, algebraic properties of the functional facilitate the use of fast iterative projection schemes. For the basic OT problem, the corresponding iterative scaling method is often referred to as the IPFP or Sinkhorn-Knopp algorithm~\cite{DemingStephanIPFP,sinkhorn1967diagonal}. It also can be understood as an application of the iterative Bregman projection method~\cite{bregman1967relaxation} for projection with respect to the Kullback-Leibler divergence of a Gibbs kernel onto the transportation polytope. This approach to OT can be vectorized~\cite{cuturi-2013} to run on massively parallel architectures like GPGPUs and thus is applied to the computation of OT barycenters involving thousands of measures as in~\cite{CuturiBarycenter}.

% our approach
% Following~\cite{Benamou-IterBregman-2014}, we propose adapting a similar approach to OT problems on manifolds rather than discrete domains. The key bottleneck we address is the ability to integrate pairwise geodesic distances into this framework without precomputing and storing a gigantic matrix of pairwise distances. This is made possible by the simple---but powerful---observation that Bregman projections only require the \emph{application} of the geodesic Gibbs kernel. This kernel can be approximated efficiently by the heat kernel~\cite{varadhan-1967}, a well-studied operator in graphics and geometry processing. This observation is at the heart of the ``heat method'' to compute geodesic distances~\cite{crane-2013}, which can be understood as OT between pairs of Diracs. We extend this concept to more general problems involving densities rather than pairs of Diracs.

%\leo{Except for mention's of Justin's, Quentin's, and Keenan's work, the above paragraphs do not survey the graphics-specific transportation literature. Although we do mention graphics applications in the introduction section, it may be wise to add a paragraph with more of that here --- at least mention~\cite{bonneel-2011}.}
% In graphics, transportation problems have been introduced for shape matching~\cite{lipman-2011}, shape analysis~\cite{solomon-2014}, image processing~\cite{rabin-2011}, sampling~\cite{degoes-2012}, shape reconstruction~\cite{degoes-2011}, caustics~\cite{schwartzburg-2014}, rendering~\cite{bonneel-2011}, joint image segmentation and matching~\cite{schmitzer-2014}, image interpolation~\cite{zhu-2007}, BRDF interpolation~\cite{bonneel-2011}, and other tasks.  